CREATE TABLE senses (
  id uuid unique primary key NOT NULL, -- generated by client via uuidv4 so they can create a sense offline and keep adding to it
  entry_id text NOT NULL, -- add REFERENCES entries (id) once Firestore data migrated
  created_at timestamp with time zone DEFAULT now() NOT NULL,
  created_by text NOT NULL, -- add REFERENCES auth.users (id) once Firestore data migrated
  updated_at timestamp with time zone DEFAULT now() NOT NULL,
  updated_by text NOT NULL, -- add REFERENCES auth.users (id) once Firestore data migrated
  glosses jsonb, -- object
  parts_of_speech jsonb, -- array
  semantic_domains jsonb, -- array
  write_in_semantic_domains jsonb, -- array
  noun_class character varying,
  definition_english_deprecated text,
  deleted timestamp with time zone
);

ALTER TABLE senses ENABLE ROW LEVEL SECURITY;
CREATE POLICY "Anyone can view senses"
ON senses FOR SELECT
USING ( true );

CREATE TYPE entry_tables AS ENUM ('entry', 'senses', 'audio', 'videos', 'photos', 'speakers');

CREATE TABLE entry_updates (
  id uuid unique primary key NOT NULL, -- generated by client via uuidv4 so it can be idempotent and they can send it multiple times without repeated effect in case of network issues
  user_id text NOT NULL, -- add REFERENCES auth.users (id) once Firestore data migrated and set this in a trigger once we have auth connected
  dictionary_id text NOT NULL, -- add REFERENCES dictionaries (id) once Firestore data migrated
  entry_id text NOT NULL, -- add REFERENCES entries (id) once Firestore data migrated
  "timestamp" timestamp with time zone DEFAULT now() NOT NULL,
  "table" entry_tables NOT NULL,
  "row" text NOT NULL, -- initially just the sense id, but later also entry id, photo id, etc.
  "column" text NOT NULL,
  old_value text,
  new_value text NOT NULL
);

ALTER TABLE entry_updates ENABLE ROW LEVEL SECURITY;

CREATE FUNCTION apply_entry_updates()
RETURNS TRIGGER AS $$
DECLARE
    column_type regtype;
    formatted_new_value text;
BEGIN
  -- Determine the data type of the target column in the target table
  SELECT INTO column_type data_type
  FROM information_schema.columns
  WHERE table_name = NEW.table AND column_name = NEW.column;

  -- If the target column is of type jsonb, attempt to parse the new_value
  IF column_type = 'jsonb' THEN
    BEGIN
      -- Try to parse the new_value as jsonb
      formatted_new_value := NEW.new_value::jsonb::text;
    EXCEPTION WHEN others THEN
      -- If parsing fails, keep the new_value as text
      formatted_new_value := NEW.new_value;
    END;
  ELSE
    -- If the target column is not jsonb, use the new_value as is
    formatted_new_value := NEW.new_value;
  END IF;

  EXECUTE format(
    'INSERT INTO %I 
    (id, %I, created_at, updated_at, created_by, updated_by) 
    VALUES (%L, %L, now(), now(), %L, %L) 
    ON CONFLICT (id) DO UPDATE 
    SET %I = %L, updated_at = now(), updated_by', 
    NEW.table, 
    NEW.column, 
    NEW.row, 
    formatted_new_value,
    NEW.user_id,
    NEW.user_id,
    NEW.column, 
    formatted_new_value,
    NEW.user_id
  );
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

CREATE TRIGGER on_entry_updates
AFTER INSERT ON entry_updates
FOR EACH ROW
EXECUTE FUNCTION apply_entry_updates();